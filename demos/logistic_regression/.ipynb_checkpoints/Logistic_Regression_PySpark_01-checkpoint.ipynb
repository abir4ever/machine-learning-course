{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Example by Spark/PySpark\n",
    "\n",
    "# source: \n",
    "#   building model: https://docs.databricks.com/_static/notebooks/binary-classification.html\n",
    "#   data: https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "# import SparkSession\n",
    "# SparkSession : The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "# A SparkSession can be used create DataFrame, register DataFrame as tables, execute \n",
    "# SQL over tables, cache tables, and read parquet files. To create a SparkSession, use \n",
    "# the following builder pattern:\n",
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Word Count\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.93:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x119338550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education_num',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_per_week',\n",
       " 'native_country',\n",
       " 'income']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', \n",
    "             'education_num', 'marital_status', 'occupation', \n",
    "             'relationship', 'race', 'sex', 'capital_gain', \n",
    "             'capital_loss', 'hours_per_week',\n",
    "             'native_country', 'income']\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+--------+-------------+-------------+----------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|age|workclass        |fnlwgt  |education    |education_num|marital_status        |occupation        |relationship  |race               |sex    |capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+---+-----------------+--------+-------------+-------------+----------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|39 | State-gov       |77516.0 | Bachelors   |13.0         | Never-married        | Adm-clerical     | Not-in-family| White             | Male  |2174.0      |0.0         |40.0          | United-States| <=50K|\n",
      "|50 | Self-emp-not-inc|83311.0 | Bachelors   |13.0         | Married-civ-spouse   | Exec-managerial  | Husband      | White             | Male  |0.0         |0.0         |13.0          | United-States| <=50K|\n",
      "|38 | Private         |215646.0| HS-grad     |9.0          | Divorced             | Handlers-cleaners| Not-in-family| White             | Male  |0.0         |0.0         |40.0          | United-States| <=50K|\n",
      "|53 | Private         |234721.0| 11th        |7.0          | Married-civ-spouse   | Handlers-cleaners| Husband      | Black             | Male  |0.0         |0.0         |40.0          | United-States| <=50K|\n",
      "|28 | Private         |338409.0| Bachelors   |13.0         | Married-civ-spouse   | Prof-specialty   | Wife         | Black             | Female|0.0         |0.0         |40.0          | Cuba         | <=50K|\n",
      "|37 | Private         |284582.0| Masters     |14.0         | Married-civ-spouse   | Exec-managerial  | Wife         | White             | Female|0.0         |0.0         |40.0          | United-States| <=50K|\n",
      "|49 | Private         |160187.0| 9th         |5.0          | Married-spouse-absent| Other-service    | Not-in-family| Black             | Female|0.0         |0.0         |16.0          | Jamaica      | <=50K|\n",
      "|52 | Self-emp-not-inc|209642.0| HS-grad     |9.0          | Married-civ-spouse   | Exec-managerial  | Husband      | White             | Male  |0.0         |0.0         |45.0          | United-States| >50K |\n",
      "|31 | Private         |45781.0 | Masters     |14.0         | Never-married        | Prof-specialty   | Not-in-family| White             | Female|14084.0     |0.0         |50.0          | United-States| >50K |\n",
      "|42 | Private         |159449.0| Bachelors   |13.0         | Married-civ-spouse   | Exec-managerial  | Husband      | White             | Male  |5178.0      |0.0         |40.0          | United-States| >50K |\n",
      "|37 | Private         |280464.0| Some-college|10.0         | Married-civ-spouse   | Exec-managerial  | Husband      | Black             | Male  |0.0         |0.0         |80.0          | United-States| >50K |\n",
      "|30 | State-gov       |141297.0| Bachelors   |13.0         | Married-civ-spouse   | Prof-specialty   | Husband      | Asian-Pac-Islander| Male  |0.0         |0.0         |40.0          | India        | >50K |\n",
      "|23 | Private         |122272.0| Bachelors   |13.0         | Never-married        | Adm-clerical     | Own-child    | White             | Female|0.0         |0.0         |30.0          | United-States| <=50K|\n",
      "|32 | Private         |205019.0| Assoc-acdm  |12.0         | Never-married        | Sales            | Not-in-family| Black             | Male  |0.0         |0.0         |50.0          | United-States| <=50K|\n",
      "|40 | Private         |121772.0| Assoc-voc   |11.0         | Married-civ-spouse   | Craft-repair     | Husband      | Asian-Pac-Islander| Male  |0.0         |0.0         |40.0          | ?            | >50K |\n",
      "|34 | Private         |245487.0| 7th-8th     |4.0          | Married-civ-spouse   | Transport-moving | Husband      | Amer-Indian-Eskimo| Male  |0.0         |0.0         |45.0          | Mexico       | <=50K|\n",
      "|25 | Self-emp-not-inc|176756.0| HS-grad     |9.0          | Never-married        | Farming-fishing  | Own-child    | White             | Male  |0.0         |0.0         |35.0          | United-States| <=50K|\n",
      "|32 | Private         |186824.0| HS-grad     |9.0          | Never-married        | Machine-op-inspct| Unmarried    | White             | Male  |0.0         |0.0         |40.0          | United-States| <=50K|\n",
      "|38 | Private         |28887.0 | 11th        |7.0          | Married-civ-spouse   | Sales            | Husband      | White             | Male  |0.0         |0.0         |50.0          | United-States| <=50K|\n",
      "|43 | Self-emp-not-inc|292175.0| Masters     |14.0         | Divorced             | Exec-managerial  | Unmarried    | White             | Female|0.0         |0.0         |45.0          | United-States| >50K |\n",
      "+---+-----------------+--------+-------------+-------------+----------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_path = './data/adult/adult.data'\n",
    "\n",
    "# .read => denotes DataFrameReader\n",
    "# read data and create a data set\n",
    "dataset = spark.read\\\n",
    "   .format(\"csv\")\\\n",
    "   .option(\"header\",\"true\")\\\n",
    "   .option(\"inferSchema\", \"true\")\\\n",
    "   .load(input_path)\\\n",
    "\n",
    "dataset.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+--------+-------------+------+\n",
      "|age|workclass        |fnlwgt  |education    |income|\n",
      "+---+-----------------+--------+-------------+------+\n",
      "|39 | State-gov       |77516.0 | Bachelors   | <=50K|\n",
      "|50 | Self-emp-not-inc|83311.0 | Bachelors   | <=50K|\n",
      "|38 | Private         |215646.0| HS-grad     | <=50K|\n",
      "|53 | Private         |234721.0| 11th        | <=50K|\n",
      "|28 | Private         |338409.0| Bachelors   | <=50K|\n",
      "|37 | Private         |284582.0| Masters     | <=50K|\n",
      "|49 | Private         |160187.0| 9th         | <=50K|\n",
      "|52 | Self-emp-not-inc|209642.0| HS-grad     | >50K |\n",
      "|31 | Private         |45781.0 | Masters     | >50K |\n",
      "|42 | Private         |159449.0| Bachelors   | >50K |\n",
      "|37 | Private         |280464.0| Some-college| >50K |\n",
      "|30 | State-gov       |141297.0| Bachelors   | >50K |\n",
      "|23 | Private         |122272.0| Bachelors   | <=50K|\n",
      "|32 | Private         |205019.0| Assoc-acdm  | <=50K|\n",
      "|40 | Private         |121772.0| Assoc-voc   | >50K |\n",
      "|34 | Private         |245487.0| 7th-8th     | <=50K|\n",
      "|25 | Self-emp-not-inc|176756.0| HS-grad     | <=50K|\n",
      "|32 | Private         |186824.0| HS-grad     | <=50K|\n",
      "|38 | Private         |28887.0 | 11th        | <=50K|\n",
      "|43 | Self-emp-not-inc|292175.0| Masters     | >50K |\n",
      "+---+-----------------+--------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.select('age', 'workclass', 'fnlwgt', 'education', 'income').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education_num',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_per_week',\n",
       " 'native_country',\n",
       " 'income']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = dataset.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPreprocess Data\\nSince we are going to try algorithms like Logistic Regression, \\nwe will have to convert the categorical variables in the dataset \\ninto numeric variables. There are 2 ways we can do this.\\n\\nCategory Indexing\\n\\n    This is basically assigning a numeric value to each category \\n    from {0, 1, 2, ...numCategories-1}. This introduces an implicit \\n    ordering among your categories, and is more suitable for ordinal \\n    variables (eg: Poor: 0, Average: 1, Good: 2)\\n\\nOne-Hot Encoding\\n\\n    This converts categories into binary vectors with at most one \\n    nonzero value (eg: (Blue: [1, 0]), (Green: [0, 1]), (Red: [0, 0]))\\n\\nIn this dataset, we have ordinal variables like education (Preschool - Doctorate), \\nand also nominal variables like relationship (Wife, Husband, Own-child, etc). For \\nsimplicity's sake, we will use One-Hot Encoding to convert all categorical variables \\ninto binary vectors. It is possible here to improve prediction accuracy by converting \\neach categorical column with an appropriate method.\\n\\nHere, we will use a combination of StringIndexer and OneHotEncoderEstimator \\nto convert the categorical variables. The OneHotEncoderEstimator will return \\na SparseVector.\\n\\nSince we will have more than 1 stage of feature transformations, we use a \\nPipeline to tie the stages together. This simplifies our code.\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocess Data\n",
    "Since we are going to try algorithms like Logistic Regression, \n",
    "we will have to convert the categorical variables in the dataset \n",
    "into numeric variables. There are 2 ways we can do this.\n",
    "\n",
    "Category Indexing\n",
    "\n",
    "    This is basically assigning a numeric value to each category \n",
    "    from {0, 1, 2, ...numCategories-1}. This introduces an implicit \n",
    "    ordering among your categories, and is more suitable for ordinal \n",
    "    variables (eg: Poor: 0, Average: 1, Good: 2)\n",
    "\n",
    "One-Hot Encoding\n",
    "\n",
    "    This converts categories into binary vectors with at most one \n",
    "    nonzero value (eg: (Blue: [1, 0]), (Green: [0, 1]), (Red: [0, 0]))\n",
    "\n",
    "In this dataset, we have ordinal variables like education (Preschool - Doctorate), \n",
    "and also nominal variables like relationship (Wife, Husband, Own-child, etc). For \n",
    "simplicity's sake, we will use One-Hot Encoding to convert all categorical variables \n",
    "into binary vectors. It is possible here to improve prediction accuracy by converting \n",
    "each categorical column with an appropriate method.\n",
    "\n",
    "Here, we will use a combination of StringIndexer and OneHotEncoderEstimator \n",
    "to convert the categorical variables. The OneHotEncoderEstimator will return \n",
    "a SparseVector.\n",
    "\n",
    "Since we will have more than 1 stage of feature transformations, we use a \n",
    "Pipeline to tie the stages together. This simplifies our code.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code basically indexes each categorical column \n",
    "# using the StringIndexer, and then converts the indexed categories \n",
    "# into one-hot encoded variables. The resulting output has the \n",
    "# binary vectors appended to the end of each row.\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    # encoder = OneHotEncoderEstimator(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"classVec\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_e69acebe7c8d,\n",
       " OneHotEncoderEstimator_44a1923b2750,\n",
       " StringIndexer_186aa27ad3e6,\n",
       " OneHotEncoderEstimator_323a17d47218,\n",
       " StringIndexer_095873925c46,\n",
       " OneHotEncoderEstimator_8891a1c97166,\n",
       " StringIndexer_f6e12eb123b1,\n",
       " OneHotEncoderEstimator_cf1c1f9f1dc6,\n",
       " StringIndexer_902b659754ee,\n",
       " OneHotEncoderEstimator_93da782a5647,\n",
       " StringIndexer_2c47e0bdb71f,\n",
       " OneHotEncoderEstimator_1718879f4211,\n",
       " StringIndexer_544c9e5450fc,\n",
       " OneHotEncoderEstimator_ae02f827ddd5,\n",
       " StringIndexer_8ce2a228156a,\n",
       " OneHotEncoderEstimator_c55aeb978323]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the StringIndexer again to encode our labels to label indices.\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_e69acebe7c8d,\n",
       " OneHotEncoderEstimator_44a1923b2750,\n",
       " StringIndexer_186aa27ad3e6,\n",
       " OneHotEncoderEstimator_323a17d47218,\n",
       " StringIndexer_095873925c46,\n",
       " OneHotEncoderEstimator_8891a1c97166,\n",
       " StringIndexer_f6e12eb123b1,\n",
       " OneHotEncoderEstimator_cf1c1f9f1dc6,\n",
       " StringIndexer_902b659754ee,\n",
       " OneHotEncoderEstimator_93da782a5647,\n",
       " StringIndexer_2c47e0bdb71f,\n",
       " OneHotEncoderEstimator_1718879f4211,\n",
       " StringIndexer_544c9e5450fc,\n",
       " OneHotEncoderEstimator_ae02f827ddd5,\n",
       " StringIndexer_8ce2a228156a,\n",
       " OneHotEncoderEstimator_c55aeb978323,\n",
       " StringIndexer_1ff91a1af058]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a VectorAssembler to combine all the feature columns into a \n",
    "# single vector column. This includes both the numeric columns and \n",
    "# the one-hot encoded binary vector columns in our dataset.\n",
    "\n",
    "# Transform all features into a vector using VectorAssembler\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_e69acebe7c8d,\n",
       " OneHotEncoderEstimator_44a1923b2750,\n",
       " StringIndexer_186aa27ad3e6,\n",
       " OneHotEncoderEstimator_323a17d47218,\n",
       " StringIndexer_095873925c46,\n",
       " OneHotEncoderEstimator_8891a1c97166,\n",
       " StringIndexer_f6e12eb123b1,\n",
       " OneHotEncoderEstimator_cf1c1f9f1dc6,\n",
       " StringIndexer_902b659754ee,\n",
       " OneHotEncoderEstimator_93da782a5647,\n",
       " StringIndexer_2c47e0bdb71f,\n",
       " OneHotEncoderEstimator_1718879f4211,\n",
       " StringIndexer_544c9e5450fc,\n",
       " OneHotEncoderEstimator_ae02f827ddd5,\n",
       " StringIndexer_8ce2a228156a,\n",
       " OneHotEncoderEstimator_c55aeb978323,\n",
       " StringIndexer_1ff91a1af058,\n",
       " VectorAssembler_f1cfbc5faa40]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the stages as a Pipeline. \n",
    "# This puts the data through all of the feature transformations we described in a single call.\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "  \n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(dataset)\n",
    "preppedDataDF = pipelineModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education_num: double, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: double, capital_loss: double, hours_per_week: double, native_country: string, income: string, workclassIndex: double, workclassclassVec: vector, educationIndex: double, educationclassVec: vector, marital_statusIndex: double, marital_statusclassVec: vector, occupationIndex: double, occupationclassVec: vector, relationshipIndex: double, relationshipclassVec: vector, raceIndex: double, raceclassVec: vector, sexIndex: double, sexclassVec: vector, native_countryIndex: double, native_countryclassVec: vector, label: double, features: vector]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preppedDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_649fa0f39dff, numClasses = 2, numFeatures = 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education_num: double, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: double, capital_loss: double, hours_per_week: double, native_country: string, income: string, workclassIndex: double, workclassclassVec: vector, educationIndex: double, educationclassVec: vector, marital_statusIndex: double, marital_statusclassVec: vector, occupationIndex: double, occupationclassVec: vector, relationshipIndex: double, relationshipclassVec: vector, raceIndex: double, raceclassVec: vector, sexIndex: double, sexclassVec: vector, native_countryIndex: double, native_countryclassVec: vector, label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ROC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit model to prepped data\n",
    "lrModel = LogisticRegression().fit(preppedDataDF)\n",
    "\n",
    "# ROC for training data\n",
    "display(lrModel, preppedDataDF, \"ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_649fa0f39dff, numClasses = 2, numFeatures = 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education_num: double, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: double, capital_loss: double, hours_per_week: double, native_country: string, income: string, workclassIndex: double, workclassclassVec: vector, educationIndex: double, educationclassVec: vector, marital_statusIndex: double, marital_statusclassVec: vector, occupationIndex: double, occupationclassVec: vector, relationshipIndex: double, relationshipclassVec: vector, raceIndex: double, raceclassVec: vector, sexIndex: double, sexclassVec: vector, native_countryIndex: double, native_countryclassVec: vector, label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lrModel, preppedDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector, age: int, workclass: string, fnlwgt: double, education: string, education_num: double, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: double, capital_loss: double, hours_per_week: double, native_country: string, income: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep relevant columns\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22838\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# You can read more about Logistic Regression from the classification and \n",
    "# regression section of MLlib Programming Guide. In the Pipelines API, \n",
    "# we are now able to perform Elastic-Net Regularization with Logistic Regression, \n",
    "# as well as other linear methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, probability: vector, age: int, occupation: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "# You can select any columns in the above schema to view as well. For example's sake we will choose age & occupation\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "|label|prediction|probability                             |age|occupation     |\n",
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "|0.0  |0.0       |[0.6923453279519433,0.3076546720480568] |26 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6211553145296423,0.37884468547035766]|30 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6584529417752994,0.3415470582247006] |31 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6582662002284263,0.34173379977157375]|32 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6150342380572296,0.3849657619427704] |39 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.5398608213408302,0.46013917865916976]|47 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6004473238924508,0.39955267610754913]|50 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.589862498197214,0.41013750180278596] |51 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.5824187454881695,0.4175812545118305] |60 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.5920153502136111,0.407984649786389]  |61 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.8373436664620277,0.1626563335379723] |26 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.989886823991184,0.01011317600881597] |20 | Prof-specialty|\n",
      "|0.0  |1.0       |[0.41522833169039547,0.5847716683096045]|35 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.7201783306056969,0.2798216693943031] |48 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.6826025206983956,0.31739747930160433]|27 | Prof-specialty|\n",
      "|0.0  |0.0       |[0.7581980543483322,0.24180194565166774]|20 | Craft-repair  |\n",
      "|0.0  |0.0       |[0.6572979526100348,0.3427020473899652] |28 | Craft-repair  |\n",
      "|0.0  |0.0       |[0.5615300820029173,0.43846991799708274]|32 | Craft-repair  |\n",
      "|0.0  |0.0       |[0.5499193207680368,0.45008067923196315]|36 | Craft-repair  |\n",
      "|0.0  |0.0       |[0.5102354119581309,0.48976458804186906]|46 | Craft-repair  |\n",
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "|label|prediction|probability                             |age|occupation     |\n",
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "|1.0  |1.0       |[0.2535583150731027,0.7464416849268972] |41 | Prof-specialty|\n",
      "|1.0  |1.0       |[0.20737798172699914,0.7926220182730008]|42 | Prof-specialty|\n",
      "|1.0  |1.0       |[0.22291188767425668,0.7770881123257433]|52 | Prof-specialty|\n",
      "|1.0  |1.0       |[0.4053769739216828,0.5946230260783171] |40 | Prof-specialty|\n",
      "|1.0  |0.0       |[0.7074755052614815,0.2925244947385185] |29 | Prof-specialty|\n",
      "|1.0  |0.0       |[0.622138267748489,0.37786173225151093] |37 | Prof-specialty|\n",
      "|1.0  |0.0       |[0.5759428639453484,0.4240571360546516] |39 | Prof-specialty|\n",
      "|1.0  |0.0       |[0.5373214942301673,0.4626785057698326] |55 | Prof-specialty|\n",
      "|1.0  |1.0       |[0.38970819989569183,0.6102918001043083]|34 | Prof-specialty|\n",
      "|1.0  |1.0       |[0.28794378401126286,0.7120562159887371]|68 | Prof-specialty|\n",
      "+-----+----------+----------------------------------------+---+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "selected.filter(col(\"label\") == 1.0).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014206228690932"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "\n",
    "# We can use BinaryClassificationEvaluator to evaluate our model. \n",
    "# We can set the required column names in rawPredictionCol and \n",
    "# labelCol Param and the metric in metricName Param.\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the default metric for the BinaryClassificationEvaluator is areaUnderROC\n",
    "\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
